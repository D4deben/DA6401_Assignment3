# PartA: Vanilla Seq2Seq Model

This section of the repository is dedicated to the implementation and evaluation of a **Vanilla Sequence-to-Sequence (Seq2Seq) model** for character-level transliteration. This model serves as a fundamental baseline, demonstrating the core Encoder-Decoder architecture without incorporating an attention mechanism.

## Core Concepts

The vanilla Seq2Seq model operates in two main phases:

1.  **Encoding**: An encoder (typically a Recurrent Neural Network like LSTM or GRU) reads the entire input sequence and compresses all the information into a fixed-size vector, known as the "context vector" or "thought vector."
2.  **Decoding**: A decoder (another RNN) takes this context vector as its initial hidden state and then generates the output sequence one token at a time. At each step, it predicts the next output token based on its current hidden state and the previously generated token.

A limitation of this architecture is that the entire input sequence must be compressed into a single fixed-size vector, which can become a bottleneck for long input sequences.

## Repository Contents:

* **`DL_Assignment4PartA.ipynb`**: This Jupyter Notebook contains the complete code for the Vanilla Seq2Seq model.
    * **Model Architecture**:
        * **`Encoder(nn.Module)`**: Implements the encoder part. It embeds the input characters and processes them through multiple layers of RNN cells (LSTM, GRU, or vanilla RNN). It supports bidirectional processing, which allows the encoder to capture context from both past and future characters in the input sequence. The `forward` method returns the final hidden state(s) of the RNN, which serve as the context vector for the decoder.
        * **`Decoder(nn.Module)`**: Implements the decoder part. It takes the embedded previous output character and the current hidden state to predict the next character in the sequence. It uses the `fc_out` linear layer to project the hidden state to the size of the output vocabulary.
        * **`Seq2Seq(nn.Module)`**: This is the main Seq2Seq wrapper class that connects the `Encoder` and `Decoder`. It handles:
            * **Hidden State Adaptation**: A crucial step (`_adapt_encoder_hidden_for_decoder`) to transform the encoder's final hidden state(s) into the correct shape and dimension expected by the decoder's initial hidden state, especially when dealing with bidirectional encoders or differing numbers of layers between encoder and decoder.
            * **Teacher Forcing**: During training, it uses a `teacher_forcing_ratio` to decide whether to feed the actual previous target token (teacher forcing) or the model's own prediction as input to the decoder for the next step. This helps stabilize training.
            * **Inference Methods**: Includes `predict_greedy` and `predict_beam_search` for generating output sequences during evaluation. `predict_greedy` selects the most probable token at each step, while `predict_beam_search` explores multiple high-probability sequences simultaneously for potentially better results.
    * **Data Handling**:
        * **`Vocabulary` Class**: Manages the mapping between characters and their integer IDs. It includes special tokens (`<sos>`, `<eos>`, `<pad>`, `<unk>`) essential for sequence models. It builds the vocabulary from the training data, allowing for custom minimum frequency thresholds.
        * **`TransliterationDataset` Class**: A standard PyTorch `Dataset` that reads transliteration pairs from TSV files (e.g., `hi.translit.sampled.train.tsv`). It handles optional `max_len` filtering to discard overly long sequences.
        * **`collate_fn` Function**: A custom collation function for PyTorch `DataLoader`. It's responsible for padding sequences within each batch to a uniform length, which is required for efficient tensor operations on GPUs.
    * **Training and Evaluation Functions**:
        * `_train_one_epoch`: Manages the training loop for a single epoch, including forward pass, loss calculation (using `nn.CrossEntropyLoss` and ignoring padding tokens), backpropagation, and gradient clipping (`torch.nn.utils.clip_grad_norm_`) to prevent exploding gradients. It also calculates exact-match training accuracy.
        * `_evaluate_one_epoch`: Performs evaluation on validation or test sets, calculating loss and exact-match accuracy using the `predict_greedy` or `predict_beam_search` methods.
    * **Hyperparameter Management**: The notebook sets up and logs experiments to Weights & Biases (W&B). It includes a `BEST_HYPERPARAMETERS` dictionary, which you should ideally update with the optimal parameters found from your own hyperparameter sweeps.
* **`predictions_vanilla/Q5.csv`**:
    * This CSV file contains the raw predictions generated by the trained Vanilla Seq2Seq model on the `hi.translit.sampled.test.tsv` dataset.
    * **Format**: Each row typically contains `Input (Latin)`, `True Output (Devanagari)`, `Model Prediction (Devanagari)`, and `Correct?` (a boolean indicating exact match). This file is crucial for comparing model performance and identifying specific areas of strength or weakness.

## How to Run:

1.  **Data Setup**: Ensure the Dakshina Hindi transliteration dataset (`hi.translit.sampled.train.tsv`, `.dev.tsv`, `.test.tsv`) is located at the path specified in the notebook's `BASE_DATA_DIR` (default for Kaggle is `/kaggle/input/dakshina-dl-a3/dakshina_dataset_v1.0/hi/lexicons/`). If your data is elsewhere, modify this path in the notebook.
2.  **Environment Setup**: Install all required Python packages as listed in the main `README.md` and ensure you have logged into Weights & Biases via `wandb login`.
3.  **Execute Notebook**: Open `DL_Assignment4PartA.ipynb` in a Jupyter environment (e.g., Jupyter Lab, Google Colab) and run all cells sequentially. The notebook is designed to train the model, evaluate it, save predictions, and log results to your W&B project automatically.

Upon successful execution, you will find training and validation metrics logged to your W&B dashboard, alongside a saved CSV file of test predictions in the `predictions_vanilla/` directory.
